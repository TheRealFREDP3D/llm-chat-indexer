# LLM Provider API Keys - Add your API keys for the LLM service you want to use
# GOOGLE_API_KEY=your_google_api_key_here        # Required for Gemini models
# OPENAI_API_KEY=your_openai_key_here          # Required for OpenAI models
# ANTHROPIC_API_KEY=your_anthropic_key_here    # Required for Anthropic models
# GROQ_API_KEY=your_groq_key_here              # Required for Groq models

# Add any provider API key supported by LiteLLM and/or compatible with the OpenAI API.
# --------------------------

# Configuration

BASE_DIR=./input                                     # Root directory for input files
OUTPUT_DIR=./output                                  # Directory for output files
SUMMARY_FILENAME=chat_summaries.md                   # Generated summary filename
INDEX_FILENAME=chat_index.json                       # Generated index filename
LLM_PROVIDER=gemini/gemini-2.0-flash                  # LLM provider and model to use
LLM_API_KEY=your_api_key_here                        # API key for chosen provider
SUPPORTED_FILE_EXTENSIONS=.txt,.md,.json,.html,.csv  # Comma-separated list of supported extensions
MAX_TOPIC_KEYWORDS=5                                 # Maximum number of topics per file
LOG_LEVEL=INFO                                       # Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_FILE=logs/chat_indexer.log                      # Path to log file
